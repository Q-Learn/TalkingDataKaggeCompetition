{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TalkingData Mobile User Demographics (Kaggle Competition)\n",
    "1. Data preprocessing\n",
    "2. Benchmark models: random forest and naive bayes\n",
    "3. Leave one out encoding\n",
    "4. Hierarchical data of multiple levels \n",
    "5. XGBoost\n",
    "6. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# numpy, scipy, and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# scikit-learn for machine learning\n",
    "from sklearn import preprocessing, metrics, grid_search, cross_validation#, pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# xgboost and keras\n",
    "import xgboost as xgb\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras.layers.advanced_activations import SReLU\n",
    "from keras.layers.core import Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load Data of Phone Brand and Device Model\n",
      "# Load Training Data\n",
      "# Load Testing Data\n",
      "# Data Loaded.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 186716 entries, 56800 to 106263\n",
      "Data columns (total 6 columns):\n",
      "age             74645 non-null float64\n",
      "device_id       186716 non-null object\n",
      "gender          74645 non-null object\n",
      "group           74645 non-null object\n",
      "phone_brand     186716 non-null object\n",
      "device_model    186716 non-null object\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# load Data\n",
    "\n",
    "print(\"# Load Data of Phone Brand and Device Model\")\n",
    "phone_brand = pd.read_csv(\"../input/phone_brand_device_model.csv\", dtype={'device_id': np.str})\n",
    "phone_brand.drop_duplicates('device_id', keep='first', inplace=True)\n",
    "\n",
    "print(\"# Load Training Data\")\n",
    "train_data = pd.read_csv(\"../input/gender_age_train.csv\", dtype={'device_id': np.str})\n",
    "\n",
    "print(\"# Load Testing Data\")\n",
    "test_data = pd.read_csv(\"../input/gender_age_test.csv\", dtype={'device_id': np.str})\n",
    "\n",
    "full_data = pd.concat((train_data, test_data), axis=0, ignore_index=True)\n",
    "train_size = len(train_data)\n",
    "full_data = pd.merge(full_data, phone_brand, how='left', on='device_id', left_index=True)\n",
    "\n",
    "print (\"# Data Loaded.\")\n",
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('target group names:', array(['F23-', 'F24-26', 'F27-28', 'F29-32', 'F33-42', 'F43+', 'M22-',\n",
      "       'M23-26', 'M27-28', 'M29-31', 'M32-38', 'M39+'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "# label/encode target\n",
    "LBL = preprocessing.LabelEncoder()\n",
    "Y = LBL.fit_transform(full_data['group'][:train_size])\n",
    "Y_labels = np_utils.to_categorical(Y)\n",
    "\n",
    "target_names = LBL.classes_\n",
    "print (\"target group names:\", target_names)\n",
    "device_id = full_data[train_size:][\"device_id\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2. Benchmark models: random forest and naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186716, 1730) (186716, 2)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "full_ohe = pd.get_dummies(full_data[['phone_brand', 'device_model']], sparse=True)\n",
    "full_ohe = sparse.csr_matrix(full_ohe)\n",
    "\n",
    "# lable encoding\n",
    "full_le = pd.DataFrame()\n",
    "full_le['phone_brand'] = LBL.fit_transform(full_data['phone_brand'])\n",
    "full_le['device_model'] = LBL.fit_transform(full_data['device_model'])\n",
    "\n",
    "print full_ohe.shape, full_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-4.169452 -   3.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... , score=-4.053912 -   3.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-3.956223 -   3.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-3.818557 -   3.8s\n",
      "('grid scores:', [mean: -3.99956, std: 0.12890, params: {}])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:   13.6s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   13.7s finished\n"
     ]
    }
   ],
   "source": [
    "# random forest with label encoding\n",
    "model = grid_search.GridSearchCV(RandomForestClassifier(n_estimators=100), \n",
    "                                 param_grid={}, \n",
    "                                 scoring='log_loss',\n",
    "                                 n_jobs=1,\n",
    "                                 iid=True,\n",
    "                                 cv=4, \n",
    "                                 refit=False,\n",
    "                                 verbose=10)\n",
    "model.fit(full_le[:train_size], Y)\n",
    "print (\"grid scores:\", model.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-3.917806 -  43.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:   43.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... , score=-3.836170 -  43.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-3.776902 -  45.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-3.626046 -  42.7s\n",
      "('grid scores:', [mean: -3.78925, std: 0.10667, params: {}])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:  2.9min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "# random forest with one hot encoding\n",
    "model = grid_search.GridSearchCV(RandomForestClassifier(n_estimators=100), \n",
    "                                 param_grid={}, \n",
    "                                 scoring='log_loss',\n",
    "                                 n_jobs=1,\n",
    "                                 iid=True,\n",
    "                                 cv=4, \n",
    "                                 refit=False,\n",
    "                                 verbose=10)   \n",
    "model.fit(full_ohe[:train_size], Y)\n",
    "print (\"grid scores:\", model.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-2.420795 -   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-2.421838 -   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-2.426279 -   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=-2.426900 -   0.1s\n",
      "('grid scores:', [mean: -2.42395, std: 0.00267, params: {}])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# naive bayes with label encoding\n",
    "model = grid_search.GridSearchCV(GaussianNB(), \n",
    "                                 param_grid={}, \n",
    "                                 scoring='log_loss',\n",
    "                                 n_jobs=1,\n",
    "                                 iid=True,\n",
    "                                 cv=4, \n",
    "                                 refit=False,\n",
    "                                 verbose=10)   \n",
    "model.fit(full_le[:train_size], Y)\n",
    "print (\"grid scores:\", model.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3. Leave one out encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function for leave one out encoding\n",
    "def loo_encode(data,cat_col,target_col,train_size,random_rate=0.05):\n",
    "    print (\"leave one out encoding %s on %s\" % (cat_col, target_col))\n",
    "    aggr = data[:train_size].groupby(cat_col)[target_col].agg([np.mean,np.size,np.sum]).reset_index()\n",
    "    data = pd.merge(data, aggr, how='left', on=cat_col)\n",
    "    data['loo'] = data['mean']\n",
    "    data['loo'][:train_size] = data[:train_size].apply(lambda row: 0 if row['size']<=1 \n",
    "        else (row['sum']-row[target_col])/(row['size']-1)*random.uniform(1-random_rate, 1+random_rate), axis=1).values\n",
    " \n",
    "    return data['loo'].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label/encode target \"gender\" \n",
    "full_data['gender'] = full_data['gender'].apply(lambda x:1 if x=='F' else 0)\n",
    "\n",
    "# concatenate \"phone_brand\" and \"device_model\" to create a new categorical feature\n",
    "full_data['brand_model'] = full_data['phone_brand'] + full_data['device_model']\n",
    "cat_cols = ['phone_brand', 'device_model', 'brand_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave one out encoding phone_brand on age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiq209/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave one out encoding phone_brand on gender\n",
      "leave one out encoding device_model on age\n",
      "leave one out encoding device_model on gender\n",
      "leave one out encoding brand_model on age\n",
      "leave one out encoding brand_model on gender\n"
     ]
    }
   ],
   "source": [
    "# leave one out encoding for 3 categorical features on 2 targets\n",
    "loo_cols = []\n",
    "for c in cat_cols:\n",
    "    for t in ['age','gender']:\n",
    "        loo_col=c+'_'+t+'_loo'\n",
    "        full_data[loo_col]=loo_encode(full_data[[c,t]],c,t,train_size,random_rate=0.05)\n",
    "        loo_cols.append(loo_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4. Hierarchical data of multiple levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlogloss: 2.398795\n"
     ]
    }
   ],
   "source": [
    "# use XGBclassifier as baseline\n",
    "X_train, X_val, y_train, y_val = train_test_split(full_data[loo_cols].values[:train_size], \n",
    "                                                  Y, \n",
    "                                                  train_size=.80, \n",
    "                                                  random_state=1234)\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "pred_val=clf.predict_proba(X_val)\n",
    "print (\"mlogloss: %f\" % (metrics.log_loss(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events loaded in 5.439940 seconds\n",
      "App Events loaded in 16.932818 seconds\n",
      "App Labels loaded in 0.176817 seconds\n",
      "Label Categories loaded in 0.005235 seconds\n"
     ]
    }
   ],
   "source": [
    "# load data: events, app_events, app_labels, and label_categories\n",
    "\n",
    "start = time.time()\n",
    "events = pd.read_csv(\"../input/events.csv\", dtype={'device_id': np.str})\n",
    "print (\"Events loaded in %f seconds\" %(time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "app_ev = pd.read_csv(\"../input/app_events.csv\", dtype={'device_id': np.str})\n",
    "print (\"App Events loaded in %f seconds\" %(time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "app_lab = pd.read_csv(\"../input/app_labels.csv\", dtype={'device_id': np.str})\n",
    "print (\"App Labels loaded in %f seconds\" %(time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "lab_cat = pd.read_csv(\"../input/label_categories.csv\", dtype={'device_id': np.str})\n",
    "print (\"Label Categories loaded in %f seconds\" %(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device apps labels and categories aggregated in 29.790449 seconds\n"
     ]
    }
   ],
   "source": [
    "# aggregate apps labels and categories by device\n",
    "device_app = pd.merge(events[['device_id','event_id']], app_ev[['event_id','app_id']], \n",
    "                      on='event_id')[['device_id','app_id']].drop_duplicates()\n",
    "device_label = pd.merge(device_app, app_lab, \n",
    "                        on='app_id')[['device_id','label_id']].drop_duplicates()\n",
    "device_category = pd.merge(device_label, lab_cat, \n",
    "                           on='label_id')[['device_id','category']].drop_duplicates()\n",
    "print (\"device apps labels and categories aggregated in %f seconds\" %(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60822,) (60822,) (60822,)\n"
     ]
    }
   ],
   "source": [
    "# concatenate applications, labels, and categories to a big text column for each device\n",
    "device_category = device_category.groupby(\"device_id\")[\"category\"].apply(list)\n",
    "device_label = device_label.groupby(\"device_id\")[\"label_id\"].apply(list)\n",
    "device_app = device_app.groupby(\"device_id\")[\"app_id\"].apply(list)\n",
    "del app_ev,events, lab_cat, app_lab\n",
    "print device_category.shape, device_label.shape, device_app.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group categories/labels/apps by device id and merge them into one big list\n",
    "full_data[\"category\"] = full_data[\"device_id\"].map(device_category).apply(\n",
    "    lambda x:' '.join(c for c in x) if x==x else '') \n",
    "full_data[\"label\"] = full_data[\"device_id\"].map(device_label).apply(\n",
    "    lambda x:' '.join(str(c) for c in x) if x==x else '') \n",
    "full_data[\"app\"] = full_data[\"device_id\"].map(device_app).apply(\n",
    "    lambda x:' '.join(str(c) for c in x) if x==x else '') \n",
    "\n",
    "full_data['device_model'] = full_data['device_model'].apply(lambda x:x.replace(' ','')) \n",
    "full_data['category'] = full_data['category'].apply(lambda x:x.replace(' ','')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count frequecies of each key word (brand, model, and app id), then convert the results to a sparse matrix\n",
    "counter = CountVectorizer(min_df=1)\n",
    "matrix = full_data[[\"phone_brand\", \"device_model\", \"app\"]].astype(np.str).apply(\n",
    "    lambda x: \" \".join(s for s in x), axis=1)\n",
    "matrix = counter.fit_transform(matrix)\n",
    "num_of_feature = matrix.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlogloss: 2.333892\n"
     ]
    }
   ],
   "source": [
    "# XGB baseline - brand, model, and application\n",
    "X_train, X_val, y_train, y_val = train_test_split(matrix[:train_size], Y, train_size=.80, random_state=1234)\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "pred_val = clf.predict_proba(X_val)\n",
    "print (\"mlogloss: %f\" % (metrics.log_loss(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.45477\n",
      "Will train until validation_0-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-mlogloss:2.43366\n",
      "[2]\tvalidation_0-mlogloss:2.41792\n",
      "[3]\tvalidation_0-mlogloss:2.40539\n",
      "[4]\tvalidation_0-mlogloss:2.39627\n",
      "[5]\tvalidation_0-mlogloss:2.38913\n",
      "[6]\tvalidation_0-mlogloss:2.38314\n",
      "[7]\tvalidation_0-mlogloss:2.3784\n",
      "[8]\tvalidation_0-mlogloss:2.37424\n",
      "[9]\tvalidation_0-mlogloss:2.37131\n",
      "[10]\tvalidation_0-mlogloss:2.36721\n",
      "[11]\tvalidation_0-mlogloss:2.36405\n",
      "[12]\tvalidation_0-mlogloss:2.36181\n",
      "[13]\tvalidation_0-mlogloss:2.35941\n",
      "[14]\tvalidation_0-mlogloss:2.35756\n",
      "[15]\tvalidation_0-mlogloss:2.35547\n",
      "[16]\tvalidation_0-mlogloss:2.3535\n",
      "[17]\tvalidation_0-mlogloss:2.35169\n",
      "[18]\tvalidation_0-mlogloss:2.35011\n",
      "[19]\tvalidation_0-mlogloss:2.34878\n",
      "[20]\tvalidation_0-mlogloss:2.34719\n",
      "[21]\tvalidation_0-mlogloss:2.34572\n",
      "[22]\tvalidation_0-mlogloss:2.34481\n",
      "[23]\tvalidation_0-mlogloss:2.34363\n",
      "[24]\tvalidation_0-mlogloss:2.34261\n",
      "[25]\tvalidation_0-mlogloss:2.34171\n",
      "[26]\tvalidation_0-mlogloss:2.34063\n",
      "[27]\tvalidation_0-mlogloss:2.33949\n",
      "[28]\tvalidation_0-mlogloss:2.33833\n",
      "[29]\tvalidation_0-mlogloss:2.3375\n",
      "[30]\tvalidation_0-mlogloss:2.3366\n",
      "[31]\tvalidation_0-mlogloss:2.33573\n",
      "[32]\tvalidation_0-mlogloss:2.33465\n",
      "[33]\tvalidation_0-mlogloss:2.33381\n",
      "[34]\tvalidation_0-mlogloss:2.33289\n",
      "[35]\tvalidation_0-mlogloss:2.33219\n",
      "[36]\tvalidation_0-mlogloss:2.33154\n",
      "[37]\tvalidation_0-mlogloss:2.33081\n",
      "[38]\tvalidation_0-mlogloss:2.33032\n",
      "[39]\tvalidation_0-mlogloss:2.32949\n",
      "[40]\tvalidation_0-mlogloss:2.32879\n",
      "[41]\tvalidation_0-mlogloss:2.32821\n",
      "[42]\tvalidation_0-mlogloss:2.32737\n",
      "[43]\tvalidation_0-mlogloss:2.32676\n",
      "[44]\tvalidation_0-mlogloss:2.32619\n",
      "[45]\tvalidation_0-mlogloss:2.32575\n",
      "[46]\tvalidation_0-mlogloss:2.32514\n",
      "[47]\tvalidation_0-mlogloss:2.32486\n",
      "[48]\tvalidation_0-mlogloss:2.32411\n",
      "[49]\tvalidation_0-mlogloss:2.32341\n",
      "[50]\tvalidation_0-mlogloss:2.32287\n",
      "[51]\tvalidation_0-mlogloss:2.32233\n",
      "[52]\tvalidation_0-mlogloss:2.32174\n",
      "[53]\tvalidation_0-mlogloss:2.32129\n",
      "[54]\tvalidation_0-mlogloss:2.32065\n",
      "[55]\tvalidation_0-mlogloss:2.32034\n",
      "[56]\tvalidation_0-mlogloss:2.32012\n",
      "[57]\tvalidation_0-mlogloss:2.31989\n",
      "[58]\tvalidation_0-mlogloss:2.31942\n",
      "[59]\tvalidation_0-mlogloss:2.31908\n",
      "[60]\tvalidation_0-mlogloss:2.3188\n",
      "[61]\tvalidation_0-mlogloss:2.31841\n",
      "[62]\tvalidation_0-mlogloss:2.31797\n",
      "[63]\tvalidation_0-mlogloss:2.31784\n",
      "[64]\tvalidation_0-mlogloss:2.31737\n",
      "[65]\tvalidation_0-mlogloss:2.31706\n",
      "[66]\tvalidation_0-mlogloss:2.31701\n",
      "[67]\tvalidation_0-mlogloss:2.31667\n",
      "[68]\tvalidation_0-mlogloss:2.31624\n",
      "[69]\tvalidation_0-mlogloss:2.31596\n",
      "[70]\tvalidation_0-mlogloss:2.31558\n",
      "[71]\tvalidation_0-mlogloss:2.31514\n",
      "[72]\tvalidation_0-mlogloss:2.31489\n",
      "[73]\tvalidation_0-mlogloss:2.31451\n",
      "[74]\tvalidation_0-mlogloss:2.31425\n",
      "[75]\tvalidation_0-mlogloss:2.314\n",
      "[76]\tvalidation_0-mlogloss:2.31381\n",
      "[77]\tvalidation_0-mlogloss:2.31339\n",
      "[78]\tvalidation_0-mlogloss:2.31302\n",
      "[79]\tvalidation_0-mlogloss:2.31277\n",
      "[80]\tvalidation_0-mlogloss:2.31258\n",
      "[81]\tvalidation_0-mlogloss:2.31237\n",
      "[82]\tvalidation_0-mlogloss:2.31215\n",
      "[83]\tvalidation_0-mlogloss:2.31182\n",
      "[84]\tvalidation_0-mlogloss:2.31165\n",
      "[85]\tvalidation_0-mlogloss:2.31126\n",
      "[86]\tvalidation_0-mlogloss:2.31092\n",
      "[87]\tvalidation_0-mlogloss:2.31069\n",
      "[88]\tvalidation_0-mlogloss:2.31055\n",
      "[89]\tvalidation_0-mlogloss:2.31029\n",
      "[90]\tvalidation_0-mlogloss:2.31015\n",
      "[91]\tvalidation_0-mlogloss:2.30981\n",
      "[92]\tvalidation_0-mlogloss:2.30962\n",
      "[93]\tvalidation_0-mlogloss:2.30955\n",
      "[94]\tvalidation_0-mlogloss:2.30935\n",
      "[95]\tvalidation_0-mlogloss:2.30909\n",
      "[96]\tvalidation_0-mlogloss:2.30888\n",
      "[97]\tvalidation_0-mlogloss:2.30879\n",
      "[98]\tvalidation_0-mlogloss:2.30853\n",
      "[99]\tvalidation_0-mlogloss:2.30829\n",
      "[100]\tvalidation_0-mlogloss:2.30811\n",
      "[101]\tvalidation_0-mlogloss:2.30803\n",
      "[102]\tvalidation_0-mlogloss:2.30785\n",
      "[103]\tvalidation_0-mlogloss:2.30769\n",
      "[104]\tvalidation_0-mlogloss:2.30766\n",
      "[105]\tvalidation_0-mlogloss:2.30767\n",
      "[106]\tvalidation_0-mlogloss:2.3075\n",
      "[107]\tvalidation_0-mlogloss:2.30735\n",
      "[108]\tvalidation_0-mlogloss:2.30694\n",
      "[109]\tvalidation_0-mlogloss:2.30685\n",
      "[110]\tvalidation_0-mlogloss:2.30671\n",
      "[111]\tvalidation_0-mlogloss:2.30654\n",
      "[112]\tvalidation_0-mlogloss:2.3065\n",
      "[113]\tvalidation_0-mlogloss:2.30645\n",
      "[114]\tvalidation_0-mlogloss:2.30632\n",
      "[115]\tvalidation_0-mlogloss:2.30615\n",
      "[116]\tvalidation_0-mlogloss:2.30606\n",
      "[117]\tvalidation_0-mlogloss:2.30595\n",
      "[118]\tvalidation_0-mlogloss:2.30584\n",
      "[119]\tvalidation_0-mlogloss:2.30575\n",
      "[120]\tvalidation_0-mlogloss:2.30564\n",
      "[121]\tvalidation_0-mlogloss:2.30552\n",
      "[122]\tvalidation_0-mlogloss:2.30541\n",
      "[123]\tvalidation_0-mlogloss:2.30526\n",
      "[124]\tvalidation_0-mlogloss:2.30514\n",
      "[125]\tvalidation_0-mlogloss:2.30498\n",
      "[126]\tvalidation_0-mlogloss:2.30492\n",
      "[127]\tvalidation_0-mlogloss:2.30474\n",
      "[128]\tvalidation_0-mlogloss:2.30454\n",
      "[129]\tvalidation_0-mlogloss:2.30429\n",
      "[130]\tvalidation_0-mlogloss:2.30409\n",
      "[131]\tvalidation_0-mlogloss:2.30392\n",
      "[132]\tvalidation_0-mlogloss:2.30367\n",
      "[133]\tvalidation_0-mlogloss:2.30357\n",
      "[134]\tvalidation_0-mlogloss:2.30345\n",
      "[135]\tvalidation_0-mlogloss:2.30337\n",
      "[136]\tvalidation_0-mlogloss:2.30335\n",
      "[137]\tvalidation_0-mlogloss:2.30332\n",
      "[138]\tvalidation_0-mlogloss:2.30326\n",
      "[139]\tvalidation_0-mlogloss:2.30321\n",
      "[140]\tvalidation_0-mlogloss:2.30316\n",
      "[141]\tvalidation_0-mlogloss:2.30319\n",
      "[142]\tvalidation_0-mlogloss:2.30306\n",
      "[143]\tvalidation_0-mlogloss:2.30299\n",
      "[144]\tvalidation_0-mlogloss:2.303\n",
      "[145]\tvalidation_0-mlogloss:2.303\n",
      "[146]\tvalidation_0-mlogloss:2.30278\n",
      "[147]\tvalidation_0-mlogloss:2.30258\n",
      "[148]\tvalidation_0-mlogloss:2.30257\n",
      "[149]\tvalidation_0-mlogloss:2.30248\n",
      "[150]\tvalidation_0-mlogloss:2.3023\n",
      "[151]\tvalidation_0-mlogloss:2.3022\n",
      "[152]\tvalidation_0-mlogloss:2.30217\n",
      "[153]\tvalidation_0-mlogloss:2.3021\n",
      "[154]\tvalidation_0-mlogloss:2.30207\n",
      "[155]\tvalidation_0-mlogloss:2.30202\n",
      "[156]\tvalidation_0-mlogloss:2.30196\n",
      "[157]\tvalidation_0-mlogloss:2.30178\n",
      "[158]\tvalidation_0-mlogloss:2.30167\n",
      "[159]\tvalidation_0-mlogloss:2.30165\n",
      "[160]\tvalidation_0-mlogloss:2.30173\n",
      "[161]\tvalidation_0-mlogloss:2.30164\n",
      "[162]\tvalidation_0-mlogloss:2.30147\n",
      "[163]\tvalidation_0-mlogloss:2.30133\n",
      "[164]\tvalidation_0-mlogloss:2.30129\n",
      "[165]\tvalidation_0-mlogloss:2.30135\n",
      "[166]\tvalidation_0-mlogloss:2.30139\n",
      "[167]\tvalidation_0-mlogloss:2.30136\n",
      "[168]\tvalidation_0-mlogloss:2.30135\n",
      "[169]\tvalidation_0-mlogloss:2.3013\n",
      "[170]\tvalidation_0-mlogloss:2.30126\n",
      "[171]\tvalidation_0-mlogloss:2.30121\n",
      "[172]\tvalidation_0-mlogloss:2.30112\n",
      "[173]\tvalidation_0-mlogloss:2.3011\n",
      "[174]\tvalidation_0-mlogloss:2.30097\n",
      "[175]\tvalidation_0-mlogloss:2.30093\n",
      "[176]\tvalidation_0-mlogloss:2.30082\n",
      "[177]\tvalidation_0-mlogloss:2.30079\n",
      "[178]\tvalidation_0-mlogloss:2.30058\n",
      "[179]\tvalidation_0-mlogloss:2.30051\n",
      "[180]\tvalidation_0-mlogloss:2.30042\n",
      "[181]\tvalidation_0-mlogloss:2.3004\n",
      "[182]\tvalidation_0-mlogloss:2.30032\n",
      "[183]\tvalidation_0-mlogloss:2.30029\n",
      "[184]\tvalidation_0-mlogloss:2.30015\n",
      "[185]\tvalidation_0-mlogloss:2.30017\n",
      "[186]\tvalidation_0-mlogloss:2.29997\n",
      "[187]\tvalidation_0-mlogloss:2.29988\n",
      "[188]\tvalidation_0-mlogloss:2.29973\n",
      "[189]\tvalidation_0-mlogloss:2.29967\n",
      "[190]\tvalidation_0-mlogloss:2.29959\n",
      "[191]\tvalidation_0-mlogloss:2.2995\n",
      "[192]\tvalidation_0-mlogloss:2.29945\n",
      "[193]\tvalidation_0-mlogloss:2.29933\n",
      "[194]\tvalidation_0-mlogloss:2.29918\n",
      "[195]\tvalidation_0-mlogloss:2.29909\n",
      "[196]\tvalidation_0-mlogloss:2.29907\n",
      "[197]\tvalidation_0-mlogloss:2.29895\n",
      "[198]\tvalidation_0-mlogloss:2.29892\n",
      "[199]\tvalidation_0-mlogloss:2.29885\n",
      "[200]\tvalidation_0-mlogloss:2.2988\n",
      "[201]\tvalidation_0-mlogloss:2.29875\n",
      "[202]\tvalidation_0-mlogloss:2.29874\n",
      "[203]\tvalidation_0-mlogloss:2.2988\n",
      "[204]\tvalidation_0-mlogloss:2.29878\n",
      "[205]\tvalidation_0-mlogloss:2.29877\n",
      "[206]\tvalidation_0-mlogloss:2.29874\n",
      "[207]\tvalidation_0-mlogloss:2.29854\n",
      "[208]\tvalidation_0-mlogloss:2.29849\n",
      "[209]\tvalidation_0-mlogloss:2.29849\n",
      "[210]\tvalidation_0-mlogloss:2.2984\n",
      "[211]\tvalidation_0-mlogloss:2.29837\n",
      "[212]\tvalidation_0-mlogloss:2.29821\n",
      "[213]\tvalidation_0-mlogloss:2.29827\n",
      "[214]\tvalidation_0-mlogloss:2.29822\n",
      "[215]\tvalidation_0-mlogloss:2.29816\n",
      "[216]\tvalidation_0-mlogloss:2.29821\n",
      "[217]\tvalidation_0-mlogloss:2.29813\n",
      "[218]\tvalidation_0-mlogloss:2.29811\n",
      "[219]\tvalidation_0-mlogloss:2.29803\n",
      "[220]\tvalidation_0-mlogloss:2.29801\n",
      "[221]\tvalidation_0-mlogloss:2.29799\n",
      "[222]\tvalidation_0-mlogloss:2.29811\n",
      "[223]\tvalidation_0-mlogloss:2.29801\n",
      "[224]\tvalidation_0-mlogloss:2.2979\n",
      "[225]\tvalidation_0-mlogloss:2.29782\n",
      "[226]\tvalidation_0-mlogloss:2.29759\n",
      "[227]\tvalidation_0-mlogloss:2.29743\n",
      "[228]\tvalidation_0-mlogloss:2.29745\n",
      "[229]\tvalidation_0-mlogloss:2.29732\n",
      "[230]\tvalidation_0-mlogloss:2.29742\n",
      "[231]\tvalidation_0-mlogloss:2.29732\n",
      "[232]\tvalidation_0-mlogloss:2.29722\n",
      "[233]\tvalidation_0-mlogloss:2.29715\n",
      "[234]\tvalidation_0-mlogloss:2.29713\n",
      "[235]\tvalidation_0-mlogloss:2.29702\n",
      "[236]\tvalidation_0-mlogloss:2.297\n",
      "[237]\tvalidation_0-mlogloss:2.29702\n",
      "[238]\tvalidation_0-mlogloss:2.29699\n",
      "[239]\tvalidation_0-mlogloss:2.29687\n",
      "[240]\tvalidation_0-mlogloss:2.29689\n",
      "[241]\tvalidation_0-mlogloss:2.29684\n",
      "[242]\tvalidation_0-mlogloss:2.29676\n",
      "[243]\tvalidation_0-mlogloss:2.29666\n",
      "[244]\tvalidation_0-mlogloss:2.29656\n",
      "[245]\tvalidation_0-mlogloss:2.29659\n",
      "[246]\tvalidation_0-mlogloss:2.29653\n",
      "[247]\tvalidation_0-mlogloss:2.29659\n",
      "[248]\tvalidation_0-mlogloss:2.2965\n",
      "[249]\tvalidation_0-mlogloss:2.29655\n",
      "[250]\tvalidation_0-mlogloss:2.2966\n",
      "[251]\tvalidation_0-mlogloss:2.29653\n",
      "[252]\tvalidation_0-mlogloss:2.29655\n",
      "[253]\tvalidation_0-mlogloss:2.29653\n",
      "[254]\tvalidation_0-mlogloss:2.29646\n",
      "[255]\tvalidation_0-mlogloss:2.29646\n",
      "[256]\tvalidation_0-mlogloss:2.29638\n",
      "[257]\tvalidation_0-mlogloss:2.29633\n",
      "[258]\tvalidation_0-mlogloss:2.29624\n",
      "[259]\tvalidation_0-mlogloss:2.29618\n",
      "[260]\tvalidation_0-mlogloss:2.29613\n",
      "[261]\tvalidation_0-mlogloss:2.29604\n",
      "[262]\tvalidation_0-mlogloss:2.29588\n",
      "[263]\tvalidation_0-mlogloss:2.29579\n",
      "[264]\tvalidation_0-mlogloss:2.29573\n",
      "[265]\tvalidation_0-mlogloss:2.29579\n",
      "[266]\tvalidation_0-mlogloss:2.29586\n",
      "[267]\tvalidation_0-mlogloss:2.29592\n",
      "[268]\tvalidation_0-mlogloss:2.29593\n",
      "[269]\tvalidation_0-mlogloss:2.2959\n",
      "[270]\tvalidation_0-mlogloss:2.29594\n",
      "[271]\tvalidation_0-mlogloss:2.29586\n",
      "[272]\tvalidation_0-mlogloss:2.2958\n",
      "[273]\tvalidation_0-mlogloss:2.29573\n",
      "[274]\tvalidation_0-mlogloss:2.29554\n",
      "[275]\tvalidation_0-mlogloss:2.29559\n",
      "[276]\tvalidation_0-mlogloss:2.29553\n",
      "[277]\tvalidation_0-mlogloss:2.2955\n",
      "[278]\tvalidation_0-mlogloss:2.29535\n",
      "[279]\tvalidation_0-mlogloss:2.29541\n",
      "[280]\tvalidation_0-mlogloss:2.29546\n",
      "[281]\tvalidation_0-mlogloss:2.29543\n",
      "[282]\tvalidation_0-mlogloss:2.29542\n",
      "[283]\tvalidation_0-mlogloss:2.29539\n",
      "[284]\tvalidation_0-mlogloss:2.29537\n",
      "[285]\tvalidation_0-mlogloss:2.29531\n",
      "[286]\tvalidation_0-mlogloss:2.29537\n",
      "[287]\tvalidation_0-mlogloss:2.29533\n",
      "[288]\tvalidation_0-mlogloss:2.29537\n",
      "[289]\tvalidation_0-mlogloss:2.29534\n",
      "[290]\tvalidation_0-mlogloss:2.2953\n",
      "[291]\tvalidation_0-mlogloss:2.29526\n",
      "[292]\tvalidation_0-mlogloss:2.29529\n",
      "[293]\tvalidation_0-mlogloss:2.2952\n",
      "[294]\tvalidation_0-mlogloss:2.29523\n",
      "[295]\tvalidation_0-mlogloss:2.2951\n",
      "[296]\tvalidation_0-mlogloss:2.29512\n",
      "[297]\tvalidation_0-mlogloss:2.29514\n",
      "[298]\tvalidation_0-mlogloss:2.29521\n",
      "[299]\tvalidation_0-mlogloss:2.29515\n",
      "[300]\tvalidation_0-mlogloss:2.29517\n",
      "[301]\tvalidation_0-mlogloss:2.29518\n",
      "[302]\tvalidation_0-mlogloss:2.29508\n",
      "[303]\tvalidation_0-mlogloss:2.29514\n",
      "[304]\tvalidation_0-mlogloss:2.29515\n",
      "[305]\tvalidation_0-mlogloss:2.2951\n",
      "[306]\tvalidation_0-mlogloss:2.29507\n",
      "[307]\tvalidation_0-mlogloss:2.29507\n",
      "[308]\tvalidation_0-mlogloss:2.29502\n",
      "[309]\tvalidation_0-mlogloss:2.29509\n",
      "[310]\tvalidation_0-mlogloss:2.29505\n",
      "[311]\tvalidation_0-mlogloss:2.29505\n",
      "[312]\tvalidation_0-mlogloss:2.29502\n",
      "[313]\tvalidation_0-mlogloss:2.29503\n",
      "[314]\tvalidation_0-mlogloss:2.29501\n",
      "[315]\tvalidation_0-mlogloss:2.29507\n",
      "[316]\tvalidation_0-mlogloss:2.29506\n",
      "[317]\tvalidation_0-mlogloss:2.29502\n",
      "[318]\tvalidation_0-mlogloss:2.29497\n",
      "[319]\tvalidation_0-mlogloss:2.29499\n",
      "[320]\tvalidation_0-mlogloss:2.29501\n",
      "[321]\tvalidation_0-mlogloss:2.29491\n",
      "[322]\tvalidation_0-mlogloss:2.29495\n",
      "[323]\tvalidation_0-mlogloss:2.29495\n",
      "[324]\tvalidation_0-mlogloss:2.29491\n",
      "[325]\tvalidation_0-mlogloss:2.29486\n",
      "[326]\tvalidation_0-mlogloss:2.29488\n",
      "[327]\tvalidation_0-mlogloss:2.29495\n",
      "[328]\tvalidation_0-mlogloss:2.29501\n",
      "[329]\tvalidation_0-mlogloss:2.29494\n",
      "[330]\tvalidation_0-mlogloss:2.295\n",
      "[331]\tvalidation_0-mlogloss:2.29503\n",
      "[332]\tvalidation_0-mlogloss:2.29499\n",
      "[333]\tvalidation_0-mlogloss:2.29501\n",
      "[334]\tvalidation_0-mlogloss:2.29509\n",
      "[335]\tvalidation_0-mlogloss:2.29515\n",
      "[336]\tvalidation_0-mlogloss:2.29523\n",
      "[337]\tvalidation_0-mlogloss:2.29521\n",
      "[338]\tvalidation_0-mlogloss:2.29515\n",
      "[339]\tvalidation_0-mlogloss:2.29518\n",
      "[340]\tvalidation_0-mlogloss:2.29521\n",
      "[341]\tvalidation_0-mlogloss:2.29522\n",
      "[342]\tvalidation_0-mlogloss:2.29517\n",
      "[343]\tvalidation_0-mlogloss:2.29513\n",
      "[344]\tvalidation_0-mlogloss:2.29516\n",
      "[345]\tvalidation_0-mlogloss:2.29518\n",
      "Stopping. Best iteration:\n",
      "[325]\tvalidation_0-mlogloss:2.29486\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.3, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a trick called early stopping to find out the optimal number of iterations for XGB\n",
    "clf = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.3)\n",
    "clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='mlogloss', early_stopping_rounds=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 2.29486)\n"
     ]
    }
   ],
   "source": [
    "# best_iteration = clf.best_iteration_\n",
    "# best_score = clf.best_score_\n",
    "best_iteration = 325\n",
    "best_score = 2.29486\n",
    "\n",
    "print (best_iteration, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission\n",
    "clf = xgb.XGBClassifier(n_estimators=best_iteration, learning_rate=0.3)\n",
    "clf.fit(matrix[:train_size], Y)\n",
    "pred = clf.predict_proba(matrix[train_size:])\n",
    "\n",
    "result = pd.DataFrame(pred, columns=target_names)\n",
    "result[\"device_id\"] = device_id\n",
    "result = result.set_index(\"device_id\")\n",
    "result.to_csv('brand_model_app_xgb.csv', index=True, index_label='device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert sparse matrix to dense (in batches)\n",
    "\n",
    "# generator for training\n",
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "\n",
    "# generator for predicting            \n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data for validation\n",
    "train = matrix[:train_size, :]\n",
    "test = matrix[train_size:, :]\n",
    "# num_class = 12\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, Y_labels, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create MLP model with Keras\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    #     Input Layer\n",
    "    model.add(Dense(512, \n",
    "                    input_dim=input_dim,\n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #     Hidden Layer\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #     Output Layer\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "    #     Optimizer\n",
    "    nadam = Nadam(lr=1e-4)\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=nadam)\n",
    "    return model\n",
    "\n",
    "model = create_model(num_of_feature)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "fit= model.fit_generator(generator=batch_generator(X_train, y_train, 128, True),\n",
    "                         nb_epoch=30,\n",
    "                         samples_per_epoch=train_size,\n",
    "                         vali  dation_data=(X_val.todense(), y_val),\n",
    "                         callbacks=[early_stop]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print (\"Training model %d\" % (i+1))\n",
    "    model=create_model(num_of_feature)\n",
    "    fit= model.fit_generator(generator=batch_generator(train, Y_labels, 128, True),\n",
    "                             nb_epoch=<epoch of best model>,\n",
    "                             samples_per_epoch=train.shape[0]\n",
    "                             )\n",
    "    preds=preds+model.predict_generator(generator=batch_generatorp(test, 128, False), val_samples=test.shape[0])\n",
    "    \n",
    "preds = preds/60\n",
    "submission = pd.DataFrame(preds, columns=label_group.classes_)\n",
    "submission[\"device_id\"] = device_id\n",
    "submission = submission.set_index(\"device_id\")\n",
    "submission.to_csv('submission.csv', index=True, index_label='device_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
